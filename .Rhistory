filter(is.na(STEM_teach)) %>%
select(N1SCIJOB_plotting,M1MATHJOB_plotting)
hsls$STEM_teach <- case_when((hsls$N1SCIJOB_plotting == "Missing" &
hsls$M1MATHJOB_plotting == "Missing") ~ "Missing",
(hsls$N1SCIJOB_plotting == "Yes" | hsls$M1MATHJOB_plotting == "Yes") ~ "Yes",
(hsls$M1MATHJOB_plotting == "No" & hsls$N1SCIJOB_plotting == "No") ~ "No",
(hsls$M1MATHJOB_plotting == "No" & hsls$N1SCIJOB_plotting == "Missing") ~ "No",
(hsls$M1MATHJOB_plotting == "Missing" & hsls$N1SCIJOB_plotting == "No") ~ "No")
STEM_sum <- hsls %>%
count(STEM_teach_plotting = factor(STEM_teach)) %>%
mutate(pct = prop.table(n))
STEM_sum
#hsls %>%
# filter(is.na(STEM_teach)) %>%
#select(N1SCIJOB_plotting,M1MATHJOB_plotting)
hsls$STEM_teach <- case_when((hsls$N1SCIJOB_plotting == "Missing" &
hsls$M1MATHJOB_plotting == "Missing") ~ "Missing",
(hsls$N1SCIJOB_plotting == "Yes" | hsls$M1MATHJOB_plotting == "Yes") ~ "Yes",
(hsls$M1MATHJOB_plotting == "No" & hsls$N1SCIJOB_plotting == "No") ~ "No",
(hsls$M1MATHJOB_plotting == "No" & hsls$N1SCIJOB_plotting == "Missing") ~ "No",
(hsls$M1MATHJOB_plotting == "Missing" & hsls$N1SCIJOB_plotting == "No") ~ "No")
STEM_sum <- hsls %>%
count(STEM_teach_plotting = factor(STEM_teach)) %>%
mutate(pct = prop.table(n))
STEM_sum %>%
ggplot(aes(x = STEM_teach_plotting, y = pct, label = scales::percent(pct))) +
geom_col()+
geom_text(position = position_dodge(width = .9),    # move to center of bars
vjust = -0.5,    # nudge above top of bar
size = 3) +
scale_y_continuous(labels = scales::percent)+
labs(x='Previous STEM-Related Job', y='Percent of Students',
title="Percent of Students with 9th grade STEM Teachers with Prior STEM-related Jobs")
hsls_subset_sciteacher <- subset(hsls, N1SCIJOB >=0)
dim(hsls_subset_sciteacher) #17,036 records
hsls_subset_STEMteacher <- subset(hsls, STEM_teach != "Missing")
dim(hsls_subset_STEMteacher) #15491 records
hsls_subset_mathteacher <- subset(hsls, M1MATHJOB>=0)
dim(hsls_subset_mathteacher) #17,036 records
M1MATHJOB_sum_1 <- hsls_subset_mathteacher %>%
count(M1MATHJOB_plotting = factor(M1MATHJOB_plotting)) %>%
mutate(pct = prop.table(n))
M1MATHJOB_sum_1 %>%
ggplot(aes(x = M1MATHJOB_plotting, y = pct, label = scales::percent(pct))) +
geom_col()+
geom_text(position = position_dodge(width = .9),    # move to center of bars
vjust = -0.5,    # nudge above top of bar
size = 3) +
scale_y_continuous(labels = scales::percent)+
labs(x='Previous Math Related Job', y='Percent of Respondents',
title="Percentage of Students with 9th grade Math Teachers with Math-related Jobs Prior to Teaching",
subtitle = "After Removing Missing Data")
N1SCIJOB_sum_1 <- hsls_subset_sciteacher %>%
count(N1SCIJOB_plotting = factor(N1SCIJOB_plotting)) %>%
mutate(pct = prop.table(n))
N1SCIJOB_sum_1 %>%
ggplot(aes(x = N1SCIJOB_plotting, y = pct, label = scales::percent(pct))) +
geom_col()+
geom_text(position = position_dodge(width = .9),    # move to center of bars
vjust = -0.5,    # nudge above top of bar
size = 3) +
scale_y_continuous(labels = scales::percent)+
labs(x='Previous Science-Related Job', y='Percent of Students',
title="Percentage of Students with 9th grade Science Teachers with Previous Science-related Jobs")
STEM_sum_1 <- hsls_subset_STEMteacher %>%
count(STEM_teach_plotting = factor(STEM_teach)) %>%
mutate(pct = prop.table(n))
STEM_sum_1 %>%
ggplot(aes(x = STEM_teach_plotting, y = pct, label = scales::percent(pct))) +
geom_col()+
geom_text(position = position_dodge(width = .9),    # move to center of bars
vjust = -0.5,    # nudge above top of bar
size = 3) +
scale_y_continuous(labels = scales::percent)+
labs(x='Previous STEM-Related Job', y='Percent of Students',
title="Percent of Students with 9th grade STEM Teachers with Prior STEM-related Jobs")
hsls_subset1 <- subset(hsls, X3TGPASTEM >= 0 & X3THISCI >= 0 & X3THIMATH>=0
& (M1MATHJOB>=0 | N1SCIJOB >= 0) & X1SEX >=0 & M1ALTCERT>=0 & N1ALTCERT >= 0
& M1MTHYRS912 >= 0 & N1SCIYRS912>=0
& (X4OCC1STEM1 >= 0 | X4OCCFBMRST1 >=0 | X5STEMCRED >= 0)
& X1SES >= -5
)
dim(hsls_subset1)
install.packages("Hmisc")
library(Hmisc)
#install.packages("Hmisc")
library(Hmisc)
hsls1 <- hsls
hsls1$X3TGPASTEM = ifelse(hsls1$X3TGPASTEM >= 0 , hsls1$X3TGPASTEM, null)
#install.packages("Hmisc")
library(Hmisc)
hsls1<- hsls
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED',"ENTERstem" #entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM', "AchieveSTEM" #achieve in STEM
,"student_male","student_race", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB_plotting" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED',"ENTERstem" #entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM', "AchieveSTEM" #achieve in STEM
,"student_male","student_race", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB_plotting" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED'#entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM' #achieve in STEM
,"student_male","student_race", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB_plotting" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED'#entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM' #achieve in STEM
,"X1SEX","X1RACE", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
hsls1 <- hsls %>% replace_with_na_all(condition = ~.x == -9)
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB_plotting" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED'#entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM' #achieve in STEM
,"X1SEX","X1RACE", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
hsls1 <- hsls %>% na_if(-9)
vars <- c("M1MATHJOB","N1SCIJOB", "STEM_teach", "N1SCIJOB_plotting", "M1MATHJOB_plotting" #teacher previous stem job
,"X4OCC1STEM1","X4OCCFBMRST1",'X5STEMCRED'#entrance into STEM
,"X3TGPASTEM","X3THIMATH",'X3THISCI','X3TCREDSTEM' #achieve in STEM
,"X1SEX","X1RACE", "X1SES","M1ALTCERT" ,"N1ALTCERT","M1MTHYRS912","N1SCIYRS912" #control
)
#subetting the data for what I want
hsls1 <- hsls1[,vars]
hsls1 <- hsls %>% na_if(-9) %>% na_if(-8)
#missing values imputing
#GPA
hsls1$imputed_X3TGPASTEM <- with(hsls1, impute(X3TGPASTEM, mean))
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
library(httr)
library(ggplot2)
library(tidyverse)
library(magrittr)
library(DT)
library(stringr)
library(rgdal)
library(leaflet.extras)
library(tmap)
library(tmaptools)
library(rgeos)
library(RColorBrewer)
library(sf)
library(spatialEco)
library(sp)
library(usethis)
library(units)
library(tmap)
library(devtools)
#devtools::install_github("rstudio/leaflet")
library(leaflet)
library(htmlwidgets)
library(stringr)
library(mapproj)
options(dplyr.summarise.inform = F)
options(rgdal_show_exportToProj4_warnings=none)
require(scales)
#install.packages("ggmap")
library(ggmap)
library(htmltools)
nyc_boro <- readOGR("data/nyc_boroughs_map/","nybb")
airbnb<-read.csv("data/airbnb_listings.csv")
neighborhoods <- readOGR("./data/neighbourhoods.geojson", verbose=FALSE)
airbnb <- airbnb %>%
select(id, host_id, host_name, latitude, longitude,neighbourhood_cleansed, neighbourhood_group_cleansed,room_type, accommodates, bathrooms, bedrooms, price, monthly_price, review_scores_rating, availability_365)
airbnb$price = as.numeric(gsub("\\$", "", airbnb$price))
table <- airbnb %>%
group_by(host_id, host_name) %>%
summarise(Number_of_listings = n_distinct(id),
Avg_Nightly_Price = mean(price, na.rm = TRUE),
Est_Monthly_income = sum(((price*availability_365)/12)*.8, na.rm = TRUE)
)  %>%
arrange(desc(Number_of_listings)) %>%
head(50)
datatable(table, rownames = FALSE,
filter = list(position = "top"),
options = list(language = list(sSearch = "Filter:")))
airbnb$price = as.numeric(gsub("\\$", "", airbnb$price))
table <- airbnb %>%
group_by(host_id, host_name) %>%
summarise(Number_of_listings = n_distinct(id),
Avg_Nightly_Price = mean(price, na.rm = TRUE),
Est_Monthly_income = sum(((price*availability_365)/12)*.8, na.rm = TRUE)
)  %>%
arrange(desc(Number_of_listings))
datatable(table, rownames = FALSE,
filter = list(position = "top"),
options = list(language = list(sSearch = "Filter:")))
airbnb %>%
filter(host_id == 97219)
nyc_boro <- readOGR("data/nyc_boroughs_map/","nybb")
airbnb<-read.csv("data/airbnb_listings.csv")
neighborhoods <- readOGR("./data/neighbourhoods.geojson", verbose=FALSE)
airbnb %>%
filter(host_id == 97219)
airbnb <- airbnb %>%
select(id, host_id, host_name, latitude, longitude,neighbourhood_cleansed, neighbourhood_group_cleansed,room_type, accommodates, bathrooms, bedrooms, price, monthly_price, review_scores_rating, availability_365)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tm)
library(tidytext)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(ggthemes)
library(sf)
library(DT)
library(wordcloud)
library(quanteda)
library(ggplot2)
library(magrittr)
library(dplyr)
library(ggthemes)
library(ggpubr)
library(tidyverse)
library(plotly)
library(DT)
library(ggalt)
library(ggrepel)
library(rvest)
library(stringr)
library(plotly)
all <- read.csv("~/Documents/GitHub/GBBO/GBBO_allseasons_episodes_and_status_022422.csv")
all
all
GBBO_stopwords <- c("cake",'cakes','trifle','trifles','pastry','pastries','pie'
,'pies','bar','bars','bun','buns','tatin','tarte','tart'
,'tarts','bread','breads','breadsticks','brownies')
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, removeWords, GBBO_stopwords)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
SB_Favorite<- all %>%
filter(result =="SB" | status = "Favorite")
all
GBBO_stopwords <- c("cake",'cakes','trifle','trifles','pastry','pastries','pie'
,'pies','bar','bars','bun','buns','tatin','tarte','tart'
,'tarts','bread','breads','breadsticks','brownies')
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, removeWords, GBBO_stopwords)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
SB_Favorite<- all %>%
filter(result =="SB" | status == "Favorite")
Out_Least_Favorite <- all %>%
filter(result =="OUT" | status == "Least Favorite")
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$showstopper), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$showstopper), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
all_tf
all_tf$State = case_when(all_tf$document =="1" ~ "SB_Favorite_blurb",
all_tf$document == "2" ~ "Out_Least_Favorite_blurb")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words By Success")+
scale_y_continuous(labels=abs)+
coord_flip()
all
GBBO_stopwords <- c("cake",'cakes','trifle','trifles','pastry','pastries','pie'
,'pies','bar','bars','bun','buns','tatin','tarte','tart'
,'tarts','bread','breads','breadsticks','brownies')
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, removeWords, GBBO_stopwords)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
SB_Favorite<- all %>%
filter(result =="SB" | status == "Favorite")
Out_Least_Favorite <- all %>%
filter(result =="OUT" | status == "Least Favorite")
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$showstopper), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$showstopper), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
all_tf
all_tf$State = case_when(all_tf$document =="1" ~ "SB_Favorite",
all_tf$document == "2" ~ "Out_Least_Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words By Success")+
scale_y_continuous(labels=abs)+
coord_flip()
#all
GBBO_stopwords <- c("cake",'cakes','trifle','trifles','pastry','pastries','pie'
,'pies','bar','bars','bun','buns','tatin','tarte','tart'
,'tarts','bread','breads','breadsticks','brownies')
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, c(stopwords("en")))
corpus <- tm_map(corpus, removeWords, GBBO_stopwords)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
return(corpus)
}
SB_Favorite<- all %>%
filter(result =="SB" | status == "Favorite")
Out_Least_Favorite <- all %>%
filter(result =="OUT" | status == "Least Favorite")
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$showstopper), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$showstopper), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
#all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
all_tf %>% arrange(term)
all_tf$State = case_when(all_tf$document =="1" ~ "SB or Favorite",
all_tf$document == "2" ~ "Out or Least Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words Showstopper")+
scale_y_continuous(labels=abs)+
coord_flip()
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$showstopper), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$showstopper), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
#all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
all_tf %>% arrange(term)
all_tf$State = case_when(all_tf$document =="1" ~ "SB or Favorite",
all_tf$document == "2" ~ "Out or Least Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words Showstopper")+
scale_y_continuous(labels=abs)+
coord_flip()
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$signature), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$signature), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
#all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
all_tf %>% arrange(term)
all_tf$State = case_when(all_tf$document =="1" ~ "SB or Favorite",
all_tf$document == "2" ~ "Out or Least Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words Signature")+
scale_y_continuous(labels=abs)+
coord_flip()
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$signature), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$signature), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
#all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
#all_tf %>% arrange(term)
all_tf$State = case_when(all_tf$document =="1" ~ "SB or Favorite",
all_tf$document == "2" ~ "Out or Least Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words Signature")+
scale_y_continuous(labels=abs)+
coord_flip()
SB_Favorite_blurb<-stripWhitespace(paste(c(SB_Favorite$showstopper), collapse=" " ))
Out_Least_Favorite_blurb<-stripWhitespace(paste(c(Out_Least_Favorite$showstopper), collapse=" " ))
all_blurb<-union(SB_Favorite_blurb,Out_Least_Favorite_blurb)
all_vector<-VCorpus(VectorSource(all_blurb))
all_clean<-clean_corpus(all_vector)
all_tdm <- TermDocumentMatrix(all_clean)
all_tidy <- tidy(all_tdm)
#all_tidy
all_tf <-  all_tidy %>%
bind_tf_idf(term, document, count) %>%
arrange(desc(tf))
#all_tf %>% arrange(term)
all_tf$State = case_when(all_tf$document =="1" ~ "SB or Favorite",
all_tf$document == "2" ~ "Out or Least Favorite")
top_20 = all_tf %>% group_by(term) %>%
summarise(n = sum(count)) %>%
arrange(desc(n)) %>%
head(20)
top_20_tf = all_tf %>%
filter(term %in% top_20$term) %>%
group_by(term, document, State) %>%
summarise(Frequency = sum(count))
ggplot(top_20_tf, aes(x = reorder(term, Frequency)
, y = Frequency, fill = State))+
geom_bar(data=filter(top_20_tf,document=='1'), stat='identity')+
geom_bar(data=filter(top_20_tf,document=='2'), aes(y=-Frequency), stat='identity')+
labs(x='Term', y='Count',
title="Top 20 Words Showstopper")+
scale_y_continuous(labels=abs)+
coord_flip()
